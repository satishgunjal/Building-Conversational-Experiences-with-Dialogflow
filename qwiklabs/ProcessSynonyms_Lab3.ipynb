{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Synonyms\n",
    "\n",
    "This notebook uses a combination of Python data science libraries and the Google Natural Language API (machine learning) to expand the vocabulary of the chatbot by generating synonyms for topics created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling google-cloud-datastore-1.15.0:\r\n",
      "  Successfully uninstalled google-cloud-datastore-1.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-datastore\n",
      "  Using cached https://files.pythonhosted.org/packages/40/7c/e1dec4fd96448fded7812f23be75cc3697534e7252d018499a9fb40fb9cc/google_cloud_datastore-1.15.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (1.4.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (1.22.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.52.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.13.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.19.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.20.1)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.2.0)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2018.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.10.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (41.0.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2.18.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.31.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (0.2.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2.1.0)\n",
      "Requirement already satisfied: rsa<4.6; python_version < \"3.5\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.4.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2019.3.9)\n",
      "Requirement already satisfied: enum34>=1.0.4; python_version < \"3.4\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2.0dev,>=1.29.0; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.1.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.19.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (0.4.5)\n",
      "Installing collected packages: google-cloud-datastore\n",
      "Successfully installed google-cloud-datastore-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/14/49a8afaaa66fb49cda8e60512f0fc07594232fb10ea6aa8995c069172cf6/inflect-3.0.2-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata (from inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: configparser>=3.5; python_version < \"3\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from importlib-metadata->inflect) (3.5.3)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/0a/67556e9b7782df7118c1f49bdc494da5e5e429c93aa77965f33e81287c8c/zipp-1.2.0-py2.py3-none-any.whl\n",
      "Collecting contextlib2; python_version < \"3\" (from importlib-metadata->inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pathlib2; python_version < \"3\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from importlib-metadata->inflect) (2.3.3)\n",
      "Requirement already satisfied: six in /usr/local/envs/py2env/lib/python2.7/site-packages (from pathlib2; python_version < \"3\"->importlib-metadata->inflect) (1.10.0)\n",
      "Requirement already satisfied: scandir in /usr/local/envs/py2env/lib/python2.7/site-packages (from pathlib2; python_version < \"3\"->importlib-metadata->inflect) (1.10.0)\n",
      "Installing collected packages: contextlib2, zipp, importlib-metadata, inflect\n",
      "Successfully installed contextlib2-0.6.0.post1 importlib-metadata-1.7.0 inflect-3.0.2 zipp-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit Reset Session > Restart, then resume with the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only need to do this once...\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_client = datastore.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = datastore.Client()\n",
    "query = client.query(kind='Topic')\n",
    "results = list(query.fetch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "plurals = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Synonyms with Python\n",
    "Split the topic into words and use PyDictionary to look up synonyms in a \"thesaurus\" for each word.  Store these in Datastore and link them back to the topic.  Note this section uses the concept of \"stop words\" to filter out articles and other parts of speech that don't contribute to meaning of the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/ipykernel/__main__.py:2: DeprecationWarning: the sets module is deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/unidecode/__init__.py:46: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  _warn_if_not_unicode(string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual salary annual Set([])\n",
      "annual salary salary Set([u'wage', u'salary', u'remuneration', u'pay', u'salaries', u'earnings', u'pays', u'wages', u'earning', u'remunerations'])\n",
      "compassionate leave compassionate Set([])\n",
      "compassionate leave leave Set([u'partings', u'leaves', u'farewells', u'leave', u'farewell', u'parting'])\n",
      "disability leave disability Set([u'handicap', u'disabilities', u'disability', u'disablements', u'handicaps', u'disablement', u'impairment', u'impairments'])\n",
      "disability leave leave Set([u'partings', u'leaves', u'farewells', u'leave', u'farewell', u'parting'])\n",
      "discipline discipline Set([u'discipline', u'bailiwicks', u'disciplines', u'fields', u'study', u'field', u'subjects', u'bailiwick', u'corrections', u'studies', u'correction', u'subject'])\n",
      "employee classifications employee Set([u'employee', u'employees'])\n",
      "employee classifications classifications Set([u'categorisation', u'compartmentalisations', u'categorization', u'classifications', u'compartmentalizations', u'classification', u'assortments', u'compartmentalisation', u'sorting', u'compartmentalization', u'categorisations', u'sortings', u'assortment', u'categorizations'])\n",
      "employee duties employee Set([u'employee', u'employees'])\n",
      "employee duties duties Set([u'duty', u'obligations', u'responsibilities', u'responsibility', u'obligation', u'tariff', u'tariffs', u'duties'])\n",
      "employer property employer Set([u'employers', u'employer'])\n",
      "employer property property Set([u'belonging', u'dimensions', u'places', u'holdings', u'attribute', u'prop', u'dimension', u'place', u'holding', u'props', u'belongings', u'attributes', u'property', u'properties'])\n",
      "employment equity employment Set([u'utilisation', u'use', u'engagement', u'utilization', u'work', u'usages', u'engagements', u'employ', u'exercises', u'uses', u'utilisations', u'employs', u'utilizations', u'usage', u'employments', u'works', u'employment', u'exercise'])\n",
      "employment equity equity Set([u'equities', u'fairness', u'fairnesses', u'equity'])\n",
      "group rrsp group Set([u'group', u'radical', u'radicals', u'groups', u'grouping', u'groupings'])\n",
      "group rrsp rrsp Set([])\n",
      "hours of work hours Set([u'hour', u'hr', u'hrs', u'hours', u'minutes', u'minute'])\n",
      "hours of work work Set([u'oeuvre', u'oeuvres', u'employment', u'study', u'work', u'workplaces', u'workplace', u'employments', u'works', u'studies'])\n",
      "jury duty jury Set([u'juries', u'panels', u'jury', u'panel'])\n",
      "jury duty duty Set([u'duty', u'obligations', u'responsibilities', u'responsibility', u'obligation', u'tariff', u'tariffs', u'duties'])\n",
      "layoff layoff Set([u'layoff', u'layoffs'])\n",
      "nepotism nepotism Set([u'nepotism', u'nepotisms'])\n",
      "orientation orientation Set([u'predilections', u'preferences', u'preference', u'predilection', u'orientations', u'orientation'])\n",
      "overtime overtime Set([u'overtime', u'overtimes'])\n",
      "performance appraisals performance Set([u'operations', u'functioning', u'performances', u'executions', u'functionings', u'performance', u'operation', u'execution'])\n",
      "performance appraisals appraisals Set([u'appraisals', u'appraisal', u'estimations', u'estimates', u'assessments', u'estimation', u'assessment', u'estimate'])\n",
      "personnel file personnel Set([u'personnel', u'force', u'forces', u'personnels'])\n",
      "personnel file file Set([u'files', u'file'])\n",
      "pets pets Set([u'dearies', u'duckies', u'pets', u'pet', u'darlings', u'deary', u'favorite', u'favourite', u'dearie', u'favorites', u'PETS', u'darling', u'favourites', u'PET', u'ducky'])\n",
      "probation probation Set([u'probation', u'probations'])\n",
      "professionalism professionalism Set([u'professionalism', u'professionalisms'])\n",
      "recruitment and selection recruitment Set([u'recruitment', u'enlistings', u'enlisting', u'recruitments'])\n",
      "recruitment and selection selection Set([u'excerption', u'selection', u'option', u'selections', u'excerptions', u'extract', u'survival', u'excerpt', u'choices', u'extracts', u'pick', u'picks', u'excerpts', u'choice', u'survivals', u'options'])\n",
      "renovations renovations Set([u'overhaul', u'refurbishments', u'redevelopments', u'refurbishment', u'renovations', u'restoration', u'restorations', u'renovation', u'overhauls', u'redevelopment'])\n",
      "resignation resignation Set([u'resignations', u'surrender', u'resignation', u'surrenders'])\n",
      "scents scents Set([u'perfumes', u'fragrances', u'smell', u'odor', u'aromas', u'odour', u'odours', u'perfume', u'smells', u'fragrance', u'odors', u'aroma', u'scent', u'scents'])\n",
      "sick leave sick Set([])\n",
      "sick leave leave Set([u'partings', u'leaves', u'farewells', u'leave', u'farewell', u'parting'])\n",
      "smoke free environment smoke Set([u'heater', u'fume', u'pot', u'skunks', u'fumes', u'locoweeds', u'sen', u'dopes', u'heaters', u'sess', u'fastballs', u'hummers', u'pots', u'gage', u'sens', u'fastball', u'hummer', u'dope', u'weed', u'bullets', u'weeds', u'smoking', u'smokings', u'grass', u'bullet', u'grasses', u'gages', u'smokes', u'sesses', u'smoke', u'skunk', u'locoweed'])\n",
      "smoke free environment free Set([])\n",
      "smoke free environment environment Set([u'environs', u'surrounding', u'surrounds', u'environments', u'environment', u'surroundings', u'environ', u'surround'])\n",
      "statutory holidays statutory Set([])\n",
      "statutory holidays holidays Set([u'holiday', u'vacation', u'holidays', u'vacations'])\n",
      "termination for cause termination Set([u'result', u'endpoint', u'resultant', u'expirations', u'conclusions', u'ending', u'terminations', u'resultants', u'results', u'conclusion', u'expiry', u'outcomes', u'expiries', u'outcome', u'terminus', u'expiration', u'endings', u'termination', u'endpoints', u'terminuses'])\n",
      "termination for cause cause Set([u'causas', u'crusades', u'campaign', u'reasons', u'crusade', u'causes', u'movements', u'lawsuit', u'lawsuits', u'suits', u'suit', u'causa', u'ground', u'cause', u'movement', u'drives', u'campaigns', u'reason', u'cases', u'effort', u'case', u'drive', u'efforts', u'grounds'])\n",
      "termination without cause termination Set([u'result', u'endpoint', u'resultant', u'expirations', u'conclusions', u'ending', u'terminations', u'resultants', u'results', u'conclusion', u'expiry', u'outcomes', u'expiries', u'outcome', u'terminus', u'expiration', u'endings', u'termination', u'endpoints', u'terminuses'])\n",
      "termination without cause without Set([])\n",
      "termination without cause cause Set([u'causas', u'crusades', u'campaign', u'reasons', u'crusade', u'causes', u'movements', u'lawsuit', u'lawsuits', u'suits', u'suit', u'causa', u'ground', u'cause', u'movement', u'drives', u'campaigns', u'reason', u'cases', u'effort', u'case', u'drive', u'efforts', u'grounds'])\n",
      "unpaid leave unpaid Set([])\n",
      "unpaid leave leave Set([u'partings', u'leaves', u'farewells', u'leave', u'farewell', u'parting'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from sets import Set\n",
    "\n",
    "for result in results:\n",
    "  for word in result.key.name.split():\n",
    "    \n",
    "    if word in stop:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    synonyms = Set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "      \n",
    "      if \".n.\" in str(syn):\n",
    "\n",
    "        for l in syn.lemmas():\n",
    "          lemma = l.name()\n",
    "          if (lemma.isalpha()):\n",
    "            synonyms.add(lemma)\n",
    "            synonyms.add(plurals.plural(lemma))\n",
    "      \n",
    "      if \".a.\" in str(syn):\n",
    "        synonyms = Set()\n",
    "        break\n",
    "\n",
    "    print result.key.name, word, synonyms\n",
    "    \n",
    "    kind = 'Synonym'\n",
    "    synonym_key = datastore_client.key(kind, result.key.name)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    synonym_key = datastore_client.key(kind, word)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    for dictionary_synonym in synonyms:\n",
    "      \n",
    "      synonym_key = datastore_client.key(kind, dictionary_synonym)\n",
    "\n",
    "      synonym = datastore.Entity(key=synonym_key)\n",
    "      synonym['synonym'] = result.key.name\n",
    "\n",
    "      datastore_client.put(synonym)\n",
    "      \n",
    "    synonym_key = datastore_client.key(kind, plurals.plural(word))\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
